# Crowdsourced subjective speech quality assessment database

The subjective quality of transmitted speech is traditionally assessed in a controlled laboratory environment according to ITU-T Rec. P.800. In turn, with crowdsourcing, crowdworkers participate in a subjective online experiment using their own listening device, and in their own working environment.

The work by Naderi et al. (2020) investigates the impact of the number of judgments on the reliability and the validity of quality
ratings collected through crowdsourcing-based speech quality assessments, as an input to ITU-T Rec. P.808 . Three crowdsourcing
experiments on different platforms were conducted to evaluate the overall quality of three different speech datasets, using the
Absolute Category Rating procedure. The results provide a suggestion on the required number of votes per condition, and allow to
model its impact on validity and reliability.

## Databased Description
The database is published to the community and provides the subjective data from one of the crowdsourcing studies. A detailed description of the crowdsourcing study and the results can be found in the paper below. 

## Investigators
The investigators in this research are
* Babak Naderi, 
* Tobias Hoßfeld (tobias.hossfeld@uni-wuerzburg.de), Professor and head of [Chair of Communication Networks, University of Würzburg](http://www.comnet.informatik.uni-wuerzburg.de/)
* Matthias Hirth, 
* Florian Metzger,
* Sebastian Möller, 
* Rafael Zequeira Jiménez

## Copyright Notice

Permission is hereby granted, without written agreement and without license or royalty fees, to use, copy, modify, and distribute this database and its documentation for any purpose, provided that the copyright notice in its entirety appear in all copies of this database, and the original source of this database is acknowledged in any publication that reports research using this database.

Originial source: The following paper is to be cited in the bibliography whenever the database is used.
* Babak Naderi, Tobias Hoßfeld, Matthias Hirth, Florian Metzger, Sebastian Möller, Rafael Zequeira Jiménez, "Impact of the Number of Votes on the Reliability and Validity of Subjective Speech Quality Assessment in the Crowdsourcing Approach", 2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)
